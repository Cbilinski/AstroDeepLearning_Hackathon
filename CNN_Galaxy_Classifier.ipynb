{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "g4n7icRSfQjU",
        "j9fRO54hkIQG",
        "EPAVrRGOkoa8",
        "WhmWJb54mXsQ",
        "SUHAOyWkn6SC",
        "weWq1S6up5Vt",
        "dq2YwlFupK5w",
        "tWTxd-9Tr7eA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cbilinski/AstroDeepLearning_Hackathon/blob/main/CNN_Galaxy_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Galaxy Classification using Deep Learning\n",
        "By Ansh Gupta - 02/23/2024\n",
        "\n",
        "Today, you are going to get hands-on experience making your very own machine learning models! This is a big step towards building your practical understanding of ML, and I hope this exercise encourages you to think about how you these techniques in your research. The problem we are trying to solve today is one that is very relevant in actual astronomical and machine learning research! Hopefully, after working through this notebook, you will understand the basic structure of how to train and evaluate models and can begin to make and deploy your very own.\n",
        "\n",
        "## PLEASE TAKE OUR SURVEY ONCE YOU'RE DONE!\n",
        "It really helps us make the session better for you guys and gives us extremely valuable feedback. Thank you!\n",
        "\n",
        "https://bit.ly/DeepHackFeedback"
      ],
      "metadata": {
        "id": "Jcoe4Of5v9Gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAKE SURE YOU SAVE A COPY OF THIS NOTEBOOK BEFORE YOU DO ANYTHING OR YOUR PROGRESS WILL NOT SAVE. ALSO MAKE SURE YOU ARE CONNECTED TO THE T4 GPU!"
      ],
      "metadata": {
        "id": "oiW-SAQYxd9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background"
      ],
      "metadata": {
        "id": "Jo4_iWxLcrtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the past few years (now decades, yikes!), programs like the Sloan Digital Sky Survey (SDSS) have revolutionized extragalactic astronomy and cosmology. The goal of these surveys is to create a 3-dimensional map of galaxies, quasars, and other objects in order to probe the structure of the universe on large scales. To do this, we need to know the distances to many thousands or millions of galaxies.\n",
        "\n",
        "Astronomers can measure distances to distant objects by calculating their \"redshift\". The expansion of the universe causes light travelling between us and distance sources to be stretched out, meaning that distant objects appear redder than nearby ones. We can quantify the redshift of sources by taking spectra of them, and that's exactly what surveys like SDSS do.\n",
        "\n",
        "A major part of developing and designing surveys is \"target selection\". Taking spectra is extremely expensive. SDSS used to require physical metal plates to be made with physical holes drilled in. Individual fiber optic cables would be plugged into these holes by hand, allowing spectra of multiple objects in the sky to be taken at once. Nowdays, modern surveys use tiny robots to position fiber optic cables - thousands at a time!\n",
        "\n",
        "In order to identify good candidates to take spectra of, these surveys use a set of imaging surveys for basic selection. These images (photometry) are very cheap in comparison, and help narrow down the best objects to focus on for spectroscopy. We will be analyzing images from the DESI Legacy Imaging Surveys, a program that was used to select candidates to be observed by the [Dark Energy Spectroscopic Instrument](https://www.desi.lbl.gov/)"
      ],
      "metadata": {
        "id": "rbyb-_Q2hyvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Download Dataset"
      ],
      "metadata": {
        "id": "g4n7icRSfQjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we are using is called Galaxy10 DECals. This is an improved version of an earlier dataset called Galaxy10, which used images from SDSS. Galaxy10 DECals includes images from a subset of the DESI Legacy Imaging Surveys. You can read more about it [here](https://astronn.readthedocs.io/en/latest/galaxy10.html).\n",
        "\n",
        "The data consists of images of galaxies with a resolution of 256x256 pixels in 3 color channels. There are 10 unique types of galaxies in the dataset. Every image comes with a label which tells you which class each galaxy belongs to. If we train a ML model on the images, these labels are the \"answer key\"."
      ],
      "metadata": {
        "id": "Ar9gyh1DhwTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset onto the disk\n",
        "!wget https://www.astro.utoronto.ca/~hleung/shared/Galaxy10/Galaxy10_DECals.h5"
      ],
      "metadata": {
        "id": "hdD07Ngovb_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic imports to load in and visualize the data - you definitely need these\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I had in mind to use tensorflow, but feel free to use pytorch if you prefer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, layers, models, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# I didn't use these but if you want to process the data differently you can.\n",
        "# Not advised for beginners since I already have the data processed for you!\n",
        "# import PIL\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "Wy_UToITviGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the images and labels from file\n",
        "with h5py.File('Galaxy10_DECals.h5', 'r') as F:\n",
        "    N_images = 2000\n",
        "    random_indices = np.random.choice(range(17736), size=N_images, replace=False)\n",
        "    random_indices.sort()\n",
        "\n",
        "    images = F['images'][random_indices]\n",
        "    labels = F['ans'][random_indices]"
      ],
      "metadata": {
        "id": "l7T4GCn70bSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "channels = 3\n",
        "num_classes = 10\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "orVPP8JpHTlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "VdonJt9o-Mk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = utils.split_dataset(dataset, left_size=0.8, shuffle=True, seed=42)"
      ],
      "metadata": {
        "id": "aUJI1t1s_UUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "5haHdX64FgMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "for X, Y in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(X[i].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "-ebjM6M0IZ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# READ BEFORE MOVING ON"
      ],
      "metadata": {
        "id": "uf1SPRF1jOIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have structured this notebook so that people of all experience levels will be challenged. I have snippets of code which you can use as a starting place. As you go further down the notebook, this code gets more and more detailed. So for example, absolute beginners may want to start towards the bottom, whereas people with lots of experience can start towards the top.\n",
        "\n",
        "Please try to solve as much as you can before moving on and revealing more hints. If you get stuck, you can raise your hand and I can help, or you can ask people at your table to work together and brainstorm solutions. The code snippets I provide are only meant to be a starting point if you have no clue where to start. Thanks for reading and happy coding!"
      ],
      "metadata": {
        "id": "tREbsj8qjWA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Machine Learning Experts\n",
        "\n",
        "Open this section if you are an expert and machine learning that doesn't really need help and can independently solve ML problems. You will try to design your own model from scratch and try to beat my record."
      ],
      "metadata": {
        "id": "j9fRO54hkIQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are an expert in machine learning who uses ML in their research or is very familiar with how to make your own models, I highly encourage you to start from scratch. You probably don't need me to tell you what to do, so just start with the data I have given you and try to make a model that is as good as possible! The very best I could get is a 60% validation accuracy - try and beat that record if you can! 80% or 90% is the very best I saw while browsing papers which analyzed this dataset."
      ],
      "metadata": {
        "id": "hb80JopQkK9u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oA8R7QXjkn2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Advanced Students/Researchers\n",
        "\n",
        "Open this section if you have some limited knowledge making maching learning models but not necessarily from scratch. You will be given a framework to develop your model but I won't give you much else. Good luck!"
      ],
      "metadata": {
        "id": "EPAVrRGOkoa8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will give you a basic outline for trying to build and test a model. Try to figure out a design that can get a decent validation accuracy. The best I could get is about 60%, but if you get to 30% with a simple model that would be quite successful!\n",
        "\n",
        "The outline is a sequential model, which stacks a bunch of layers on top of eachother. In this section, I will not give you any guidance on how to build up these layers. You can see the available options [here](\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
        "\n",
        "If you want some basic advice, but no specifics, here is an [article](https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7) which talks about how you might design a CNN architecture.\n"
      ],
      "metadata": {
        "id": "KB8RmCmdkvXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    layers.yourlayername(...)\n",
        "    # Add a bunch of layers like this! Good luck\n",
        "])"
      ],
      "metadata": {
        "id": "8rkPcjmVku2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='your optimizer',\n",
        "              loss='your loss',\n",
        "              metrics=['your metrics'])"
      ],
      "metadata": {
        "id": "FNrVaeKNmCFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10 # feel free to adjust\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "OI2PxpHlmGGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how good you did!"
      ],
      "metadata": {
        "id": "EkSHicStmQ9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P3tbJememOAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Intermediate Students/Researchers\n",
        "\n",
        "Open this section if you have some amount of experience solving ML problems starting off with a pre-defined architecture or tweaking existing models to solve a basic task. I will give you an outline and the right kinds of building blocks so you don't have to start from scratch, but you'll get good practice building a CNN and thinking about what layers to stack to accomplish different goals."
      ],
      "metadata": {
        "id": "WhmWJb54mXsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will give you a basic outline for trying to build and test a model. Try to figure out a design that can get a decent validation accuracy. The best I could get is about 60%, but if you get to 30% with a simple model that would be quite successful!\n",
        "\n",
        "The outline is a sequential model, which stacks a bunch of layers on top of eachother. In this section, I will not give you any guidance on how to build up these layers. You can see the available options [here](\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
        "\n",
        "If you want some basic advice, but no specifics, here is an [article](https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7) which talks about how you might design a CNN architecture.\n"
      ],
      "metadata": {
        "id": "dH9YQ7rzmu2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # This layer normalizes the data, making training more efficient\n",
        "    layers.Rescaling(1./255, input_shape=(img_height, img_width, channels)),\n",
        "\n",
        "    # Here are some examples of some layers you might stack together\n",
        "    layers.Conv2D(..., activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(..., activation='relu'),\n",
        "    layers.Dense(..., activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "QmCBgR6wFp9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9PytwmPjGSgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "dPngVT17GVBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "FUlL5WOKGX7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how good we did!"
      ],
      "metadata": {
        "id": "JHBkzi77pFR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "imAyC0DUI_yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9kPM2CNn4N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Pre-Intermediate Students/Researchers\n",
        "\n",
        "Open this section if you have some working knowledge of machine learning but haven't implemented that many models yourself. You will try to use a framework of a model I made, weaking various numbers or adding more layers, to try to come up with a good model. This is probably a good place for beginners to start too, but you can always go to the cell below if you get very stuck or are very lost."
      ],
      "metadata": {
        "id": "SUHAOyWkn6SC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will give you a slightly more detailed outline for building and testing a model. Try to figure out a good set of layers with appropriate parameters. The best valdidation accuracy I could get is about 60%, but if you get to 30% with a simple model that would be quite successful!\n",
        "\n",
        "The outline is a sequential model, which stacks a bunch of layers on top of eachother. In this section, I give a basic outline of how to build up these layers. You can see more available options for layers and the documentation for what these numbers mean [here](\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
        "\n",
        "If you want some basic advice, but no specifics, here is an [article](https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7) which talks about how you might design a CNN architecture.\n"
      ],
      "metadata": {
        "id": "Kp7erVr9n6SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # This layer normalizes the data, making training more efficient\n",
        "    layers.Rescaling(1./255, input_shape=(img_height, img_width, channels)),\n",
        "\n",
        "    # Here is an example of an architecture that's a good starting place.\n",
        "    # The ellipses are where you need to write a number that specifies how\n",
        "    # many kernels each convolutional layer makes. Ask me if you don't know\n",
        "    # what this means and I can explain. You can fiddle with these numbers\n",
        "    # based on the guidance in the second link from the text just above this\n",
        "    # cell. You can also see how I've structured this network, in rough terms,\n",
        "    # so you should experiment by adding or removing some layers if you like!\n",
        "    layers.Conv2D(..., (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(..., (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(..., (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(..., activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "4yjdHmegn6SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mgsoSvWIn6SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YioN81HFn6SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Dkt1P6P7n6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how good we did!"
      ],
      "metadata": {
        "id": "TJhELgP6pIW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o7VcEie4n6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might notice that despite our best efforts, it's really hard to get a good validation accuracy using this kind of network. Open the cell 2 below this one (Strats to Avoid Overfitting) to learn about some strategies that people use to overcome this \"overfitting barrier\"."
      ],
      "metadata": {
        "id": "HvcMG9-Ep4uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Beginners\n",
        "\n",
        "Open this section if you are a beginner and don't really know how to start. This will give you basically the full solution and you can try taking each line apart and seeing what it does. Hopefully this will give you an understanding of why we structure models the way we do, and you can fiddle with and tweak it to see what makes it work better!"
      ],
      "metadata": {
        "id": "weWq1S6up5Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will give you a complete outline of a model that will get a somewhat decent validation accuracy. By decent, I mean 30% - but keep in mind that my best attempt got to ~60% at best and state-of-the-art papers analyzing this sample reach 80-90% at most!\n",
        "\n",
        "The outline is a sequential model, which stacks a bunch of layers on top of eachother. In this section, I show you how to build up these layers. You can see more available options for layers and the documentation for what these numbers mean [here](\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
        "\n",
        "If you want some basic advice, but no specifics, here is an [article](https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7) which talks about how you might design a CNN architecture.\n"
      ],
      "metadata": {
        "id": "Dxw8I0ABp5Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # This layer normalizes the data, making training more efficient\n",
        "    layers.Rescaling(1./255, input_shape=(img_height, img_width, channels)),\n",
        "\n",
        "    # Here is an example of an architecture that's a good starting place.\n",
        "    # Try to dig through some of the documentation and understand what each\n",
        "    # line does. If you get stuck or are very confused, raise your hand\n",
        "    # and I will happily explain anything! But if you can learn it yourself,\n",
        "    # I think it'll stick even better, so give it your best shot. Feel free\n",
        "    # to fiddle with the numbers once you understand what they do! You can also\n",
        "    # see how I've structured this network, in rough terms, so you should\n",
        "    # experiment by adding or removing some layers if you like!\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "1NaFrxQFp5Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "E3wCLgXdp5Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "l2RQJE-bp5Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "6n1EQFK5p5Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how good we did!"
      ],
      "metadata": {
        "id": "OXJ3WUC9p5Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDSO7TxLp5Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might notice that despite our best efforts, it's really hard to get a good validation accuracy using this kind of network. Open the next cell to learn about some strategies that people use to overcome this \"overfitting barrier\"."
      ],
      "metadata": {
        "id": "KKaF7nlxq88V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Techniques to Avoid Overfitting\n",
        "Open this cell if you have gotten a somewhat successful model but are running into the issue of overfitting. You can implement some of these strategies in order to try taking your training further."
      ],
      "metadata": {
        "id": "dq2YwlFupK5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our models are hitting plateaus because our model is getting better and better at fitting the training data, but it's not necessarily getting better at fitting the testing data, or indeed the general population of galaxies, as a whole. You might recognize this problem as overfitting. Our models are learning features of the specific set of galaxies it's training on instead of general features common to all galaxies. We will use a few strategies to try and overcome this.\n",
        "\n",
        "One strategy is data augmentation, in which we will kind of distort some of our training data in order to \"confuse\" the model. This distortion will mean that every time the model trains, the training data is slightly different, and hopefully this will reduce overfitting.\n",
        "\n",
        "Another very common strategy is dropout. At each stage of training, we will occasionally \"kill off\" some neurons. This sounds bad, but in actuality, this adds some randomness to the way the input is processed. The end result is also a reduction in overfitting."
      ],
      "metadata": {
        "id": "ezMl5wzzrL7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "nJCEuZrSKWPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented versions of the same galaxy\n",
        "plt.figure(figsize=(5, 5))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Q4ulHoDKKYDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An example of how you might implement augmentation and dropout into your model\n",
        "model = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    # layers.Dropout(0.3),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "rH5ysXqCKY51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KvaWdFndpcrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nPfh7TGuw-Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "EjilmwlopqoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how much better our model does with these techniques!"
      ],
      "metadata": {
        "id": "cPVYqHQqr4cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9vgVCiHwpwXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a Pre-trained model\n",
        "Only open this once you're completely done with the whole rest of the notebook. This is the solution I used to get a ~50-60% validation accuracy."
      ],
      "metadata": {
        "id": "tWTxd-9Tr7eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are pre-trained sophisticated models which we can use instead of our own architecture\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input as preprocess_x\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_r"
      ],
      "metadata": {
        "id": "wGTkHNs-sCj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "base_model = InceptionResNetV2(weights='imagenet', input_shape=(256, 256, 3), include_top=False)\n",
        "# base_model = Xception(weights='imagenet', input_shape=(256, 256, 3), include_top=False)\n",
        "\n",
        "# Freeze the layers of the pre-trained ResNet50 model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "input_layer = layers.Input(shape=(256, 256, 3))\n",
        "x = preprocess_r(input_layer)\n",
        "# x = preprocess_x(input_layer)\n",
        "x = model(x)\n",
        "model = Model(inputs=input_layer, outputs=x)"
      ],
      "metadata": {
        "id": "AmQQaeoZU_O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \\\n",
        "              loss='sparse_categorical_crossentropy', \\\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0q-UXr9_sZBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWLkKoKjZSoC"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWS-vvNaZDag"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PVoalk28KzWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}